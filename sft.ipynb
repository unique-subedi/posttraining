{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM6gYPB8VcJ0uFA1TWNXJ5s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unique-subedi/posttraining/blob/main/sft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes\n",
        "!pip install -U trl"
      ],
      "metadata": {
        "id": "jfKeT7vtdiOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "0i9rqH1-pNOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j14W860lYVHY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "zxDerkTpe9K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"deepseek-ai/deepseek-llm-7b-chat\""
      ],
      "metadata": {
        "id": "5ZpoB5sjZuHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16,\n",
        ")\n"
      ],
      "metadata": {
        "id": "ChQTwCvbaJWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)"
      ],
      "metadata": {
        "id": "HUTRhp18bYKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map= \"auto\", quantization_config=bnb_config, dtype=torch.bfloat16)"
      ],
      "metadata": {
        "id": "xFCpptK4cZ61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.memory_allocated() / 1e9, \"GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iXsaCBxcwAP",
        "outputId": "9dcd88f6-fa96-4aba-9574-f80f5ba3bc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.864994816 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Finetuning Chat"
      ],
      "metadata": {
        "id": "PeDBULYLp96t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(prompt, max_new_tokens=200):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=False,\n",
        "    )\n",
        "\n",
        "    enc = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "    input_ids = enc[\"input_ids\"].to(model.device)\n",
        "    attention_mask = enc[\"attention_mask\"].to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    print(tokenizer.decode(out[0][input_ids.shape[1]:], skip_special_tokens=True))\n",
        "\n",
        "chat(\"Explain a margin call in 2 sentences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMVD-4XseqX-",
        "outputId": "48ffa0fc-a3b0-43f3-84e3-b31eaef4f784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A margin call happens when your broker requires you to add funds because your position lost value. If you don’t, the broker may sell assets to reduce risk.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LORA Setup"
      ],
      "metadata": {
        "id": "HXc6tDfMfAte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model"
      ],
      "metadata": {
        "id": "klJtzUXHfCds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache=False"
      ],
      "metadata": {
        "id": "EBaDk33BfZJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUYY3sTIfdBx",
        "outputId": "9bde86ac-1efd-40c4-ed96-c1132febdc6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 37,478,400 || all params: 6,947,844,096 || trainable%: 0.5394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "euDIuNdZgdNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "data = [\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": \"Explain what a margin call is in 2 sentences.\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"A margin call happens when your broker requires you to add funds because your position lost value. If you don’t, the broker may sell assets to reduce risk.\"},\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": \"Rewrite concisely: 'Next, we validate the conclusions of Theorem 1 with experiments.'\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"Next, we validate Theorem 1 experimentally.\"},\n",
        "        ]\n",
        "    },\n",
        "]\n",
        "\n",
        "ds = Dataset.from_list(data)\n",
        "def render(ex):\n",
        "    return {\"text\": tokenizer.apply_chat_template(ex[\"messages\"], tokenize=False)}\n",
        "\n",
        "train_ds = ds.map(render)\n",
        "\n",
        "\n",
        "print(train_ds[0][\"text\"][:400])\n"
      ],
      "metadata": {
        "id": "wb8vT6N8geWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "ExST3VRGl038"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"out\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=2e-4,\n",
        "    max_steps=50,          #\n",
        "    logging_steps=5,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        train_dataset=train_ds,\n",
        "        args=args\n",
        "    )\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "bIx7i_45jKEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "pZ70Uok5o4nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_prompts = [\n",
        "    \"Explain a margin call in 2 sentences.\",\n",
        "    \"Rewrite concisely: Next, we validate the conclusions of Theorem 1 with experiments.\",\n",
        "    \"What is overfitting in machine learning?\",\n",
        "]\n",
        "\n",
        "for p in test_prompts:\n",
        "    print(\"PROMPT:\", p)\n",
        "    chat(p)\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPyHhKrrl2zy",
        "outputId": "b6c6235c-e77a-431c-8b04-e5f582a50c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROMPT: Explain a margin call in 2 sentences.\n",
            " A margin call happens when your broker requires you to add funds because your position lost value. If you don’t, the broker may sell assets to reduce risk.\n",
            "----------------------------------------\n",
            "PROMPT: Rewrite concisely: Next, we validate the conclusions of Theorem 1 with experiments.\n",
            " Next, we validate Theorem 1 experimentally.\n",
            "----------------------------------------\n",
            "PROMPT: What is overfitting in machine learning?\n",
            " In machine learning, overfitting happens when a model learns the training data too well, to the detriment of its ability to generalize to new, unseen data. In other words, the model learns the training data so well that it starts to include noise and outliers in the training data in its decision boundary. As a result, it performs poorly on new data.\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PY8Et4Qco8Rv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}